# FINAL-CHANCE-
1. Сортировка выбором

Анализ работы алгоритма:
Сортировка выбором (Selection Sort) — метод сортировки, при котором на каждом этапе выбирается минимальный элемент из неотсортированной части массива и переносится в начало отсортированной части.

Процесс выполнения на примере массива [72, 19, 35, 41, 8]:
Шаг 1: Минимальный элемент (8) ставится первым: [8, 19, 35, 41, 72].
Шаг 2: Минимальный среди остальных (19) меняется с элементом на второй позиции: [8, 19, 35, 41, 72].
Шаг 3: Элемент 35 меняет позицию с третьим элементом: [8, 19, 35, 41, 72].
Шаг 4: Осталось минимальное значение (41) остаётся на своей позиции: [8, 19, 35, 41, 72].
ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

Лучший случай: O(n²) · Даже если массив уже отсортирован, алгоритм все равно выполнит полные проходы · Всегда выполняется двойной цикл
Средний случай: O(n²) · В среднем требуется сравнить каждый элемент с половиной оставшихся элементов
Худший случай: O(n²) · Массив отсортирован в обратном порядке · Все равно выполняется полное количество сравнений
Объяснение: Алгоритм использует два вложенных цикла. Внешний цикл проходит по всем n элементам, внутренний цикл для каждого i-го элемента проходит по (n-i) элементам. Общее количество сравнений: (n-1) + (n-2) + ... + 1 = n(n-1)/2 ∈ O(n²) Особенности: Сложность всегда O(n²), независимо от исходного порядка элементов
характеристики: простая реализация, но крайне медленно работает на больших наборах данных.

2. Сортировка обменом ("пузырьковая")

Анализ работы алгоритма:
Метод сортировки путём попарного сравнения и обмена соседних элементов. За счёт постоянного перемещения большего элемента в конец массива, этот способ напоминает всплытие пузырьков воздуха вверх.

Прохождение на примере массива [9, 5, 11, 7, 3]:
Первый проход: $[3, 5, 7, 9, 11]$ (самый большой элемент переместился).
Второй проход: $[3, 5, 7, 9, 11]$ (оставшиеся элементы также упорядочены).
ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

Худший случай: O(n²) · Массив отсортирован в обратном порядке · Количество сравнений: (n-1) + (n-2) + ... + 1 = n(n-1)/2 ∈ O(n²) · Количество обменов: такое же как сравнений
Средний случай: O(n²) · В среднем требуется n²/2 сравнений и n²/4 обменов
Лучший случай (обычная версия): O(n²) · Даже для уже отсортированного массива выполняются все проходы
Лучший случай (оптимизированная версия): O(n) · Для уже отсортированного массива достаточно одного прохода · Флаг swapped позволяет досрочно завершить сортировку
Объяснение: Два вложенных цикла. В худшем случае (обратно отсортированный массив) выполняется n-1 проходов, на каждом проходе n-1 сравнений. Всего около n² операций Особенности: В лучшем случае (отсортированный массив) с оптимизацией может быть O(n)

Ключевые характеристики: · Устойчивая сортировка - сохраняет относительный порядок одинаковых элементов · Очень медленный алгоритм для больших массивов · Простой в реализации и понимании · Хорош для обучения основам алгоритмов сортировки · Эффективен только для очень маленьких массивов или почти отсортированных данных

Сравнение с сортировкой выбором: · Пузырьковая: Много обменов, мало сравнений (в худшем случае n² обменов) · Выбором: Мало обменов (ровно n-1), много сравнений (n² сравнений) · Выбором обычно быстрее на практике из-за меньшего количества обменов

Практическое применение: Используется в основном в образовательных целях. В реальных приложениях заменяется более эффективными алгоритмами (быстрая сортировка, сортировка слиянием и др.).
3. Сортировка вставками
 анализ работы алгоритма:

Сортировка вставками (Insertion Sort) Алгоритм сортировки, который строит отсортированную последовательность постепенно, вставляя каждый новый элемент в правильную позицию относительно уже отсортированной части массива.
Принцип работы: Сортировка вставками работает по принципу обработки карт в руке. Мы начинаем с пустой "руки" (отсортированной части) и постепенно "вставляем" каждую новую карту в правильную позицию.
Работа на примере массива [14, 10, 16, 5, 7]:
Начинаем с одной карты: отсортировано — [14], не отсортировано — [10, 16, 5, 7].
Подбираем следующую карту (10) и вставляем её перед 14: [10, 14, 16, 5, 7].
Продолжаем аналогично с остальными элементами: итоговый массив — [5, 7, 10, 14, 16].

ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):
Временная сложность:

Худший случай: O(n²) · Массив отсортирован в обратном порядке · Каждый новый элемент нужно сдвигать через всю отсортированную часть · Количество операций: 1 + 2 + 3 + ... + (n-1) = n(n-1)/2 ∈ O(n²)
Средний случай: O(n²) · В среднем каждый элемент нужно сдвигать через половину отсортированной части · Количество операций: примерно n²/4
Лучший случай: O(n) · Массив уже отсортирован · Для каждого элемента выполняется только одно сравнение · Внутренний цикл while не выполняется никогда
Объяснение: Для каждого из n элементов может потребоваться сравнение и сдвиг в среднем n/2 элементов. В худшем случае (обратный порядок) каждый новый элемент нужно сдвигать через всю отсортированную часть Особенности: Адаптивный алгоритм - на частично отсортированных массивах работает быстрее
ДЕТАЛЬНЫЙ АНАЛИЗ ПОВЕДЕНИЯ:

Преимущества: · Адаптивный - работает быстрее на частично отсортированных массивах · Стабильный - сохраняет порядок одинаковых элементов · Онлайн-алгоритм - может сортировать массив по мере поступления данных · Эффективен для маленьких массивов - на практике часто используется как часть гибридных алгоритмов · Простой в реализации - интуитивно понятный алгоритм

Недостатки: · Медленный для больших массивов - квадратичная сложность делает его неэффективным для больших n · Много операций сдвига - может быть медленным при работе с linked lists

Оптимизации на практике:

Бинарный поиск для вставки - можно использовать бинарный поиск для нахождения позиции вставки (уменьшает сравнения, но не сдвиги)
Шелл-сортировка - использует идею сортировки вставками с предварительным частичным упорядочиванием
Гибридные алгоритмы - часто используется в комбинации с быстрой сортировкой для маленьких подмассивов
Сравнение с предыдущими алгоритмами: · Пузырьковая: O(n²) в лучшем случае vs Вставками: O(n) в лучшем случае · Выбором: Всегда O(n²) vs Вставками: Адаптивный, O(n) для отсортированных данных · Вставками обычно быстрее на практике из-за адаптивности

Практическое применение: · В стандартных библиотеках для сортировки маленьких массивов · В алгоритмах типа Timsort (гибрид слияния и вставок) · В реальном времени для потоковых данных · В embedded systems из-за малого потребления памяти
4. Сортировка слиянием
АНАЛИЗ РАБОТЫ АЛГОРИТМА:

Сортировка слиянием (Merge Sort) Алгоритм сортировки, использующий стратегию "разделяй и властвуй". Массив рекурсивно делится пополам до отдельных элементов, затем отсортированные части сливаются в упорядоченную последовательность.

Принцип работы: Сортировка слиянием использует стратегию "разделяй и властвуй". Алгоритм рекурсивно делит массив пополам до тех пор, пока не останутся массивы из одного элемента, затем сливает их в отсортированном порядке.
Пример выполнения на массиве [48, 32, 55, 17, 12, 60, 10]:
Разделение: уровни поделённых массивов достигают одиночных значений ([48], [32] и т.п.).
Объединение: слияние пар групп ($[32, 48]$, затем $[12, 17]$, и т.д.) до полного объединения в единый отсортированный массив — [10, 12, 17, 32, 48, 55, 60].
ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

Худший случай: O(n log n)
Средний случай: O(n log n)
Лучший случай: O(n log n)
Объяснение: Массив делится пополам log₂n раз. На каждом уровне деления выполняется слияние с O(n) операциями. Итого: O(n) × O(log n) = O(n log n) Особенности: Сложность всегда гарантирована O(n log n), но требует O(n) дополнительной памяти

Рекуррентное соотношение: T(n) = 2T(n/2) + O(n) По основной теореме: a = 2, b = 2, f(n) = O(n) → случай 2: T(n) = O(n log n)

ДЕТАЛЬНЫЙ АНАЛИЗ ПОВЕДЕНИЯ:

Преимущества: · Гарантированная производительность - всегда O(n log n) независимо от входных данных · Стабильный алгоритм - сохраняет порядок одинаковых элементов · Предсказуемое поведение - нет худшего случая деградации производительности · Параллелизуемость - левая и правая части могут сортироваться параллельно · Эффективен для внешней сортировки - хорошо работает с данными на диске

Недостатки: · Высокая пространственная сложность - требует O(n) дополнительной памяти · Не сортирует на месте - в классической реализации · Низкая производительность на маленьких массивах - из-за накладных расходов на рекурсию · Медленнее быстрой сортировки на практике - хотя имеет ту же асимптотику

Оптимизации:
Гибридный подход - использовать сортировку вставками для маленьких подмассивов (обычно n < 10-20)
Восходящая сортировка слиянием - итеративный подход без рекурсии
In-place слияние - сложные алгоритмы, позволяющие сливать без дополнительной памяти
Сравнение с предыдущими алгоритмами: · Пузырьковая/Выбором/Вставками: O(n²) vs Слиянием: O(n log n) - экспоненциальное улучшение · Вставками: O(n) в лучшем случае, но O(n²) в худшем vs Слиянием: Всегда O(n log n) · Слиянием масштабируется значительно лучше для больших массивов

Практическое применение: · В стандартных библиотеках (Java Collections.sort(), Python sorted()) · В базах данных для сортировки больших наборов данных · В алгоритмах внешней сортировки (когда данные не помещаются в память) · В MapReduce и распределенных системах · В мультимедийных приложениях для обработки больших файлов

Особенности реализации в разных языках: · Python: Возвращает новый массив, функциональный стиль · Java: Может сортировать на месте или возвращать новый массив · C++: std::stable_sort использует сортировку слиянием
5. Сортировка Шелла
Анализ работы алгоритма:

Сортировка Шелла (Shell Sort) Улучшенный вариант сортировки вставками, который сортирует элементы, расположенные на определенном расстоянии друг от друга, постепенно уменьшая это расстояние до единицы.

Ключевые этапы: · Начальный промежуток устанавливается в n/2 · Для каждого промежутка выполняется модифицированная сортировка вставками · Промежуток последовательно уменьшается вдвое до достижения 1 · Финальный проход с промежутком 1 завершает сортировку

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: · Худший случай: O(n²) - зависит от выбора последовательности промежутков · Средний случай: O(n log² n) - для оптимальных последовательностей · Лучший случай: O(n log n) - для уже частично отсортированных массивов

Объяснение: Сложность зависит от выбора последовательности промежутков. Для последовательности n/2, n/4... сложность O(n²), для оптимальных последовательностей - O(n log²n) Особенности: На практике часто работает лучше квадратичных сортировок благодаря предварительному частичному упорядочиванию
6. Быстрая сортировка
Анализ работы алгоритма:

Быстрая сортировка (Quick Sort) Эффективный алгоритм сортировки, использующий стратегию "разделяй и властвуй". Выбирается опорный элемент, массив разбивается на две части относительно опора, затем процесс рекурсивно применяется к подмассивам.

Ключевые этапы:
Пример на массиве [15, 7, 20, 10, 5]:
Выберите опорный элемент (например, 10).
После первой операции: [5, 7, 10, 20, 15].
Повторите шаги для двух половинок массива.

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: · Худший случай: O(n²) - когда опорный элемент всегда минимальный или максимальный · Средний случай: O(n log n) - при случайном выборе опорного элемента · Лучший случай: O(n log n) - когда опорный элемент делит массив пополам

Объяснение: В среднем случае массив делится пополам log n раз, на каждом уровне выполняется O(n) операций разбиения. В худшем случае (уже отсортированный массив) разбиение происходит на части размером 1 и n-1 Особенности: На практике обычно самый быстрый, но нет гарантии от худшего случая

Преимущества: Очень быстрый на практике, сортировка на месте Недостатки: Неустойчивая сортировка, производительность зависит от выбора опорного элемента
7. Пирамидальная сортировка
Анализ работы алгоритма:

Пирамидальная сортировка (Heap Sort) Алгоритм сортировки, основанный на структуре данных "двоичная куча". Сначала строится max-heap из массива, затем максимальный элемент извлекается и помещается в конец, процесс повторяется для оставшихся элементов.

Ключевые этапы:

Построение max-heap - преобразование массива в структуру двоичной кучи, где каждый родительский элемент больше своих дочерних
Сортировка - максимальный элемент (корень) перемещается в конец массива, и куча перестраивается для оставшихся элементов
Пример выполнения для массива [12, 11, 13, 5, 6, 7]: · Построение кучи: [13, 11, 12, 5, 6, 7] · Извлечение максимального: 13 перемещается в конец · Перестройка кучи для оставшихся элементов · Процесс повторяется до полной сортировки

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: O(n log n) во всех случаях (худшем, среднем, лучшем)

Объяснение: Построение кучи занимает O(n) операций, затем выполняется n извлечений максимума, каждое из которых требует O(log n) операций. Итого: O(n) + O(n log n) = O(n log n) Особенности: Всегда O(n log n), сортировка на месте, но обычно медленнее быстрой сортировки

Преимущества: Гарантированная производительность O(n log n), сортировка на месте Недостатки: Неустойчивая сортировка, медленнее чем быстрая сортировка на практике
8. Последовательный поиск
Анализ работы алгоритма:

Последовательный поиск (Linear Search) Простейший алгоритм поиска, который последовательно проверяет каждый элемент массива до тех пор, пока не найдет искомый элемент или не достигнет конца массива.

Принцип работы: · Алгоритм начинает с первого элемента массива · Последовательно сравнивает каждый элемент с искомым значением · Если элемент найден, возвращает его индекс · Если достигнут конец массива и элемент не найден, возвращает -1

Пример выполнения для массива [3, 5, 2, 7, 9, 1, 4] и target = 7: · Проверяем элемент 0: 3 ≠ 7 · Проверяем элемент 1: 5 ≠ 7 · Проверяем элемент 2: 2 ≠ 7 · Проверяем элемент 3: 7 = 7 → элемент найден на позиции 3

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: · Худший случай: O(n) - элемент находится в конце массива или отсутствует · Средний случай: O(n) - элемент находится в середине массива · Лучший случай: O(1) - элемент находится в начале массива

Объяснение: В худшем случае требуется проверить все n элементов массива. В среднем - n/2 сравнений Особенности: Работает с неотсортированными массивами, прост в реализации

Преимущества: Простота реализации, работает с неотсортированными массивами Недостатки: Медленный для больших массивов, неэффективен при частых поисках

9. Бинарный поиск
Анализ работы алгоритма:

Бинарный поиск (Binary Search) Эффективный алгоритм поиска в отсортированном массиве, который на каждом шаге делит область поиска пополам, сравнивая средний элемент с искомым значением.

Принцип работы: · Алгоритм начинает с всего массива · На каждой итерации сравнивает средний элемент с искомым значением · Если средний элемент равен целевому - поиск завершен · Если целевой элемент меньше среднего - поиск продолжается в левой половине · Если целевой элемент больше среднего - поиск продолжается в правой половине · Процесс повторяется до нахождения элемента или исчерпания области поиска

Пример выполнения для массива [1, 3, 5, 7, 9, 11, 13, 15, 17, 19] и target = 7: · Итерация 1: left=0, right=9, mid=4 → array[4]=9 > 7 → right=3 · Итерация 2: left=0, right=3, mid=1 → array[1]=3 < 7 → left=2 · Итерация 3: left=2, right=3, mid=2 → array[2]=5 < 7 → left=3 · Итерация 4: left=3, right=3, mid=3 → array[3]=7 = 7 → элемент найден

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: O(log n) · Худший случай: O(log n) - элемент находится на краю или отсутствует · Средний случай: O(log n) - элемент находится в произвольной позиции · Лучший случай: O(1) - элемент находится точно в середине массива

Объяснение: На каждом шаге область поиска уменьшается вдвое. После k шагов остается n/2^k элементов. Решая n/2^k = 1, получаем k = log₂n Особенности: Требует отсортированный массив, очень эффективен для больших массивов

Преимущества: Очень быстрый для больших отсортированных массивов Недостатки: Требует предварительной сортировки массива, не работает с несортированными данными

Важное замечание: Формула mid = left + (right - left) / 2 защищает от переполнения, которое может возникнуть при использовании mid = (left + right) / 2 для очень больших массивов.

10. Интерполирующий поиск
Анализ работы алгоритма:

Интерполирующий поиск (Interpolation Search) Улучшенная версия бинарного поиска, которая вычисляет вероятную позицию элемента на основе его значения и равномерности распределения данных в массиве.

Принцип работы: · Алгоритм использует интерполяционную формулу для предсказания позиции элемента · Формула основана на предположении о линейном распределении элементов · На каждой итерации область поиска сужается в зависимости от сравнения · Процесс повторяется до нахождения элемента или исчерпания области поиска

Интерполяционная формула: pos = low + ((target - arr[low]) * (high - low)) / (arr[high] - arr[low])

Пример выполнения для массива [10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47] и target = 18: · low=0, high=14, arr[low]=10, arr[high]=47 · pos = 0 + ((18-10)(14-0))/(47-10) = 0 + (814)/37 ≈ 3.02 → pos=3 · arr[3]=16 < 18 → low=4 · Новый диапазон: low=4, high=14 → продолжаем поиск

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: · Лучший случай: O(log log n) - для равномерно распределенных данных · Средний случай: O(log log n) - при хорошем распределении · Худший случай: O(n) - при неравномерном распределении (например, экспоненциальном)

Объяснение: При равномерном распределении данных алгоритм предсказывает позицию элемента, что позволяет быстрее сужать область поиска. В худшем случае (неравномерное распределение) вырождается в O(n) Особенности: Эффективен только при равномерном распределении данных

Преимущества: Очень быстрый для равномерно распределенных данных, превосходит бинарный поиск в лучшем случае Недостатки: Требует равномерного распределения данных, сложнее в реализации, может быть медленнее бинарного поиска при плохом распределении

Области применения: Базы данных, телефонные справочники, равномерно распределенные числовые данные

11. Фибоначчи поиск
Анализ работы алгоритма:

Поиск по Фибоначчи (Fibonacci Search) Это алгоритм поиска в отсортированном массиве, который использует числа Фибоначчи для определения позиций сравнения. Алгоритм делит массив на части, пропорциональные числам Фибоначчи.

Принцип работы:

Инициализация чисел Фибоначчи: Находим наименьшее число Фибоначчи, которое больше или равно размеру массива
Декомпозиция Фибоначчи: Используем три последовательных числа Фибоначчи для определения позиции сравнения
Сравнение и сужение диапазона: В зависимости от результата сравнения сужаем область поиска
Проверка последнего элемента: Особый случай для оставшегося элемента
Пример выполнения для массива [10, 22, 35, 40, 45, 50, 80, 82, 85, 90, 100] и target = 85: · Числа Фибоначчи: F(0)=0, F(1)=1, F(2)=1, F(3)=2, F(4)=3, F(5)=5, F(6)=8, F(7)=13 · Находим F(7)=13 ≥ 11 (размер массива) · Первая проверка: i = min(-1 + 8, 10) = 7 → arr[7]=82 < 85 · Следующая проверка: i = min(7 + 5, 10) = 10 → arr[10]=100 > 85 · И так далее до нахождения элемента на позиции 8

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: O(log n) · Худший случай: O(log n) - сравним с бинарным поиском · Средний случай: O(log n) · Лучший случай: O(1) - элемент найден на первой проверке

Объяснение: Использует числа Фибоначчи для деления массива. Как и бинарный поиск, уменьшает область поиска, но без операций деления. Количество шагов пропорционально log n Особенности: Исторически важен, но на современных процессорах обычно не превосходит бинарный поиск

Преимущества: · Избегает дорогостоящих операций деления (только сложение/вычитание) · Хорошо работает для больших массивов · Эффективен в системах, где деление дороже сложения

Недостатки: · Сложнее в реализации, чем бинарный поиск · На практике обычно не быстрее бинарного поиска на современных процессорах · Требует отсортированный массив

Сравнение с другими алгоритмами поиска: · Похож на бинарный поиск, но использует числа Фибоначчи вместо деления пополам · Может быть эффективнее в системах с ограниченными вычислительными ресурсами · Исторически важен как один из первых алгоритмов, превосходящих последовательный поиск
